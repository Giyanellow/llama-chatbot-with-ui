{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Hosting an LLM with Ollama and Llama 3.2\n",
    "\n",
    "This notebook documents the process of setting up and running a self-hosted Large Language Model (LLM) using Ollama with Llama 3.2. It includes the setup of a PostgreSQL database using Docker, the implementation of a LangChain-based backend, and the frontend built with Next.js."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of Offline LLM API Platform and Model\n",
    "\n",
    "Chose Ollama with Llama 3.2 for its robust performance and ease of integration. Ollama provides a seamless way to run LLMs locally, ensuring data privacy and reducing latency. Additionally, Llama 3.2 is a lightweight model that can perform well despite the hardware limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the PostgreSQL Database Using Docker\n",
    "\n",
    "Used Docker Compose to set up a PostgreSQL database. This simplifies the process and ensures consistency across different environments.\n",
    "\n",
    "### Steps:\n",
    "1. Create a `docker-compose.yml` file with the following content:\n",
    "```yaml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  db:\n",
    "    image: postgres:latest\n",
    "    container_name: postgres\n",
    "    environment:\n",
    "      POSTGRES_USER: admin\n",
    "      POSTGRES_PASSWORD: langchain_123\n",
    "      POSTGRES_DB: langchaindb\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "  ```\n",
    "\n",
    "2. Run the folloing command to start the PostgreSQL database:\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain with Ollama backend\n",
    "## Implementing the LangChain-Based Backend\n",
    "\n",
    "Used Flask to create the backend and LangChain to manage the chat history and interactions with the LLM.\n",
    "\n",
    "### Steps:\n",
    "#### 1. Create a `ChatBot` class in `backend/utils/chat.py`:\n",
    "```python\n",
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        self.llm = llm\n",
    "        PostgresChatMessageHistory.create_tables(sync_connection, chat_history_table)\n",
    "        self.chain = prompt | self.llm\n",
    "        self.chain_with_history = RunnableWithMessageHistory(\n",
    "            self.chain,\n",
    "            self.get_session_history,\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"history\"\n",
    "        )\n",
    "```\n",
    "\n",
    "#### 2. Create a prompt template to include memory handling\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "#### 3. Create an invoke with history method (for history context)\n",
    "```python\n",
    "\n",
    "    def run_with_history(self, input: str, session_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the chatbot with intelligent history handling\n",
    "        \n",
    "        Args:\n",
    "            input (str): User's input message\n",
    "            session_id (str): Unique identifier for the session\n",
    "        \n",
    "        Returns:\n",
    "            str: AI's response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.chain_with_history.invoke(\n",
    "                {\"input\": input},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "            \n",
    "            return response.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in run_with_history: {e}\")\n",
    "            # Fallback to simple invoke\n",
    "            return self.llm.invoke(input)\n",
    "```\n",
    "\n",
    "#### 4. Define API endpoints in `app.py`\n",
    "\n",
    "##### 4.1 Endpoint for sending a message\n",
    "```python\n",
    "@app.route('/api/send_message', methods=['POST', 'OPTIONS'])\n",
    "def send_message():\n",
    "    \"\"\"Send a message to the chatbot\n",
    "    \n",
    "    Returns:\n",
    "        Response: JSON response containing the chatbot's response\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if request.method == 'OPTIONS':\n",
    "        return _build_cors_preflight_response()\n",
    "\n",
    "    data = request.get_json()\n",
    "    prompt = data.get('message')\n",
    "    session_id = data.get('session_id')\n",
    "    \n",
    "    if not prompt:\n",
    "        return jsonify({\"error\": \"Missing 'prompt' parameter\"}), 400\n",
    "\n",
    "    if not session_id:\n",
    "        return jsonify({\"error\": \"Missing 'session_id' parameter\"}), 400\n",
    "\n",
    "    if 'session_id' not in session or session['session_id'] != session_id:\n",
    "        return jsonify({\"error\": f\"Invalid session_id: {session_id}\"}), 400\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Current Session: {session}\")\n",
    "        response = chatbot.run_with_history(prompt, session_id)\n",
    "        response_message = response if isinstance(response, str) else str(response)\n",
    "\n",
    "        return _corsify_actual_response(make_response(jsonify({\"message\": response_message})))\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        return jsonify({\"error\": f\"An error has occurred: {e}\"}), 500\n",
    "```\n",
    "\n",
    "##### 4.2 Endpoint for getting the history for the frontend\n",
    "```python\n",
    "@app.route('/api/get_message_history', methods=['POST', 'OPTIONS'])\n",
    "def get_message_history():\n",
    "    \"\"\"Get the message history for the user\n",
    "\n",
    "    Returns:\n",
    "        Response: JSON response containing the message history\n",
    "    \"\"\"\n",
    "    \n",
    "    if request.method == 'OPTIONS':\n",
    "        return _build_cors_preflight_response()\n",
    "    \n",
    "    data = request.json\n",
    "    session_id = data.get('session_id')\n",
    "    \n",
    "    if not session_id:\n",
    "        return jsonify({\"error\": \"Missing 'session_id' parameter\"}), 400\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Fetching message history for session_id: {session_id}\")\n",
    "        messages = chatbot.get_message_history(session_id)\n",
    "        if not messages:\n",
    "            return _corsify_actual_response(make_response(jsonify({\"messages\": [], \"info\": \"No messages found\"}))), 200\n",
    "        \n",
    "        return _corsify_actual_response(make_response(jsonify({\"messages\": messages}))), 200\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        return jsonify({\"error\": f\"Invalid session_id: {session_id}\"}), 500\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of Frontend Library and Implementation\n",
    "Chose Next.js for its powerful features and ease of use. It allows us to build a modern, responsive UI with server-side rendering. Considering that React has a massive amount of support for documentation and from its community - developing React with Next.js will be faster and reliable.\n",
    "\n",
    "### Steps:\n",
    "#### 1. Create a `Chat` component in `frontend/components/chat.tsx`:\n",
    "```tsx\n",
    "export default function Chat() {\n",
    "  `Kindly see the chat.tsx file for a complete view`\n",
    "}\n",
    "```\n",
    "\n",
    "#### 2. Within the `Chat` component, create an `apiClient` const\n",
    "```tsx\n",
    "  const apiClient = axios.create({\n",
    "    baseURL: process.env.NEXT_PUBLIC_BACKEND_URL,\n",
    "    withCredentials: true, // Ensure cookies are included in requests\n",
    "    headers: {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "    },\n",
    "  })\n",
    "```\n",
    "\n",
    "#### 3. Handling of sessions\n",
    "```tsx\n",
    "  const handleNewSession = async () => {\n",
    "    try {\n",
    "      const response = await apiClient.get(\"api/get_session_id\")\n",
    "      console.log(\n",
    "        \"Received new session ID from backend\",\n",
    "        response.data.session_id\n",
    "      )\n",
    "      // Set session_id cookie\n",
    "      const sessionId = response.data.session_id\n",
    "      if (sessionId) {\n",
    "        cookies.set(\"session_id\", sessionId, { path: \"/\" })\n",
    "        setMessages([])\n",
    "      }\n",
    "    } catch (error) {\n",
    "      console.error(\"Error fetching new session ID:\", error)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  const handleOldSession = async () => {\n",
    "    try {\n",
    "      const response = await apiClient.post(\"api/get_message_history\", {\n",
    "        session_id: cookies.get(\"session_id\"),\n",
    "      })\n",
    "      console.log(\"Response of request\", response)\n",
    "      setMessages(response.data.messages)\n",
    "    } catch (error) {\n",
    "      console.error(\"Error fetching message history:\", error)\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "#### 4. Sending message to the backend\n",
    "```tsx\n",
    "  const handleSubmit = async (e: React.FormEvent) => {\n",
    "    e.preventDefault()\n",
    "    if (input.trim()) {\n",
    "      setMessages((prevMessages) => [\n",
    "        ...prevMessages,\n",
    "        { id: prevMessages.length, role: \"user\", content: input },\n",
    "      ])\n",
    "      setInput(\"\")\n",
    "      setIsReplying(true)\n",
    "\n",
    "      try {\n",
    "        const response = await apiClient.post(\"api/send_message\", {\n",
    "          message: input,\n",
    "          session_id: cookies.get(\"session_id\"),\n",
    "        })\n",
    "\n",
    "        setIsReplying(false)\n",
    "\n",
    "        setMessages((prevMessages) => [\n",
    "          ...prevMessages,\n",
    "          {\n",
    "            id: prevMessages.length,\n",
    "            role: \"assistant\",\n",
    "            content: response.data.message,\n",
    "          },\n",
    "        ])\n",
    "      } catch (error) {\n",
    "        console.error(error)\n",
    "        setMessages((prevMessages) => [\n",
    "          ...prevMessages,\n",
    "          {\n",
    "            id: prevMessages.length,\n",
    "            role: \"assistant\",\n",
    "            content: \"I'm sorry, I don't understand that.\",\n",
    "          },\n",
    "        ])\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "``` Encountered an issue with session persistence through cookies - had to look up in stack overflow what the probable reason as to why Flask doesn't retain session cookies in-between requests, it is said that Flask doesn't work well with frontends running at a different port. Since Flask doesn't handle cookies well when the frontend is running in a different port, cookies are manually sent from the backend then the frontend stores it manually.```\n",
    "```tsx\n",
    "      const sessionId = response.data.session_id\n",
    "      if (sessionId) {\n",
    "        cookies.set(\"session_id\", sessionId, { path: \"/\" })\n",
    "        setMessages([])\n",
    "      }```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot tests\n",
    "Created tests with `pytest` and `pytest-flask` libraries\n",
    "\n",
    "### Steps:\n",
    "#### 1. Setup Flask application for testing in `backend/conftest.py`\n",
    "```python\n",
    "@pytest.fixture\n",
    "def app():\n",
    "    flask_app.config['TESTING'] = True\n",
    "    return flask_app\n",
    "\n",
    "@pytest.fixture\n",
    "def client(app):\n",
    "    return app.test_client()\n",
    "```\n",
    "\n",
    "#### 2. Create classes for each kind of tests in `backend/tests/test_app.py`\n",
    "```python\n",
    "class TestSessionEndpoints\n",
    "\n",
    "class TestMessageHistoryEndpoints\n",
    "\n",
    "class TestSendMessageEndpoints\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
